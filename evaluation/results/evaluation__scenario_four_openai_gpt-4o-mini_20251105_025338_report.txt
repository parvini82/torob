================================================================================
SCENARIO EVALUATION REPORT
================================================================================

EVALUATION METADATA
----------------------------------------
Scenario: scenario_four
Model Name: scenario_four_openai_gpt-4o-mini
Prediction File: /home/peyma/projects/torob/evaluation/scenario_predictions/predictions_scenario_four_openai_gpt-4o-mini_Ground_Truth_first10.json
Total Samples: 10
Timestamp: 2025-11-05T02:53:38.366833

MODEL EXECUTION PERFORMANCE
----------------------------------------
Successful Predictions: 10
Failed Predictions:     0
Success Rate:           100.0%
Avg Time/Product:       112.185s

EXACT MATCHING (MAVE-style)
----------------------------------------
Precision (Micro)	0.0000
Recall (Micro)		0.0000
F1 (Micro)		0.0000
Precision (Macro)	0.0000
Recall (Macro)		0.0000
F1 (Macro)		0.0000
Exact Match Rate	0.0000

SIMILARITY METRICS
----------------------------------------
Jaccard			0.0890
Dice			0.1599
Semantic Match Rate	0.8710
Weighted Semantic Rate	0.8710

PARTIAL EVALUATION
----------------------------------------
Partial Precision	0.0000
Partial Recall		0.0000
Partial F1		0.0000

LENIENT EVALUATION
----------------------------------------
Lenient Precision	0.0000
Lenient Recall		0.0000
Lenient F1		0.0000

ADDITIONAL
----------------------------------------
ROUGE-1			0.2234