================================================================================
COMPREHENSIVE MODEL EVALUATION REPORT
================================================================================

EVALUATION METADATA
----------------------------------------
Model Name: gpt-4o__gpt-4o-mini
Prediction File: /home/p_naseri/projects/torob/evaluation/predictions/predictions_gpt-4o__gpt-4o-mini_Ground_Truth_first10.json
Total Samples: 10
Timestamp: 2025-11-04T06:31:10.415421

MODEL EXECUTION PERFORMANCE
----------------------------------------
Successful Predictions: 9
Failed Predictions:     1
Success Rate:           90.0%
Avg Time/Product:       121.740s

EXACT MATCHING (MAVE-style)
----------------------------------------
Precision (Micro)	0.2128
Recall (Micro)		0.1449
F1 (Micro)		0.1724
Precision (Macro)	0.0603
Recall (Macro)		0.0606
F1 (Macro)		0.0597
Exact Match Rate	0.0000

SIMILARITY METRICS
----------------------------------------
Jaccard			0.1132
Dice			0.1866
Semantic Match Rate	0.6465
Weighted Semantic Rate	0.6465

PARTIAL EVALUATION
----------------------------------------
Partial Precision	0.2692
Partial Recall		0.1613
Partial F1		0.1997

LENIENT EVALUATION
----------------------------------------
Lenient Precision	0.5222
Lenient Recall		0.2792
Lenient F1		0.3252

ADDITIONAL
----------------------------------------
ROUGE-1			0.4034