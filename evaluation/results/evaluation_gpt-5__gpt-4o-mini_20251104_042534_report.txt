================================================================================
COMPREHENSIVE MODEL EVALUATION REPORT
================================================================================

EVALUATION METADATA
----------------------------------------
Model Name: gpt-5__gpt-4o-mini
Prediction File: /home/p_naseri/projects/torob/evaluation/predictions/predictions_gpt-5__gpt-4o-mini_Ground_Truth_first10.json
Total Samples: 10
Timestamp: 2025-11-04T04:25:34.524334

MODEL EXECUTION PERFORMANCE
----------------------------------------
Successful Predictions: 10
Failed Predictions:     0
Success Rate:           100.0%
Avg Time/Product:       53.965s

EXACT MATCHING (MAVE-style)
----------------------------------------
Precision (Micro)	0.1404
Recall (Micro)		0.2319
F1 (Micro)		0.1749
Precision (Macro)	0.0328
Recall (Macro)		0.0401
F1 (Macro)		0.0351
Exact Match Rate	0.0000

SIMILARITY METRICS
----------------------------------------
Jaccard			0.0778
Dice			0.1395
Semantic Match Rate	0.8282
Weighted Semantic Rate	0.8282

PARTIAL EVALUATION
----------------------------------------
Partial Precision	0.0953
Partial Recall		0.1557
Partial F1		0.1147

LENIENT EVALUATION
----------------------------------------
Lenient Precision	0.2013
Lenient Recall		0.2967
Lenient F1		0.2348

ADDITIONAL
----------------------------------------
ROUGE-1			0.3599